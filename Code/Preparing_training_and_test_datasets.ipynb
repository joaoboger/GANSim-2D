{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our training (or test) dataset includes synthesized facies models, corresponding global features, well facies dataset, and probability maps. \n",
    "\n",
    "#### In our study, facies models (2D, 64x64) are generated using the object-based modeling method, in Petrel software. \n",
    "Synthesized facies models are exported from Petrel as model properties with \"Gslib\" format into one file. \n",
    "\n",
    "\n",
    "First lines of the exported file are like:\n",
    "\n",
    "PETREL: Properties\n",
    "\n",
    "17820  % Number of synthesized facies models\n",
    "\n",
    "\n",
    "Facies unit1 scale1  \n",
    "\n",
    "Facies unit1 scale1\n",
    "\n",
    "...\n",
    "\n",
    "Facies unit1 scale1\n",
    "\n",
    "% Totally, there are 64x64 lines, corresponding to 64x64 pixels in each facies model; each line has 17820 numbers splitted by space, corresponding to 17820 facies code values of 17820 generated facies realizations at each pixel. 0-background mud faceis, 1-channel sand facies, 2-channel bank facies. \n",
    "\n",
    "0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 1.000000 2.000000\n",
    "\n",
    "0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000\n",
    "\n",
    "...\n",
    "\n",
    "0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000\n",
    "\n",
    "\n",
    "\n",
    "The 17820 facies models in this file will be enlarged (by reversing the 17820 facies models) and arranged into (35640, 1, 64, 64) in the following code.\n",
    "\n",
    "Other software, like SGeMS, can also be used, as long as the final generated facies models are arranged into (N, 1, 64, 64).\n",
    "\n",
    "\n",
    "#### Original global features (as labels in this file) include channel orientation, channel width, channel wavelength, and channel amplitude, which are corresponding input parameters when synthesizing facies models with object-based method. We further add background mud proportion and channel sinuosity index global features. \n",
    "\n",
    "#### Probability maps are produced from the synthesized facies models using Gaussian kernel smoothing method.\n",
    "\n",
    "\n",
    "#### Well facies data are sampled from the probability data . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Write paths\n",
    "#### Filepath: path of synthesized facies models\n",
    "#### labels_path: path of global features (labels) corresponding to facies models\n",
    "#### tfrecord_dir_training: directory to save training dataset\n",
    "#### tfrecord_dir_test: directory to save test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Filepath = '/home/users/suihong/training_data/TrainingData(MultiChannels_Version4)/2D_AllPro_Gslib_fromPetrel(version4)' \n",
    "labels_path = '/home/users/suihong/training_data/TrainingData(MultiChannels_Version4)/labels(version4).txt' \n",
    "tfrecord_dir_training = r'H:\\repos\\GeoModeling_GANSim-2D_Condition_to_Well_Facies_and_Global_Features\\Trainingdata\\DataSets(MultiChannels_Version4_Consistency)\\TrainingData\\'\n",
    "tfrecord_dir_test = r'H:\\repos\\GeoModeling_GANSim-2D_Condition_to_Well_Facies_and_Global_Features\\Trainingdata\\DataSets(MultiChannels_Version4_Consistency)\\TestData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Load facies models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allele=[]  \n",
    "# stores all facies code values of the file. includes 64x64 lists, and each list includes code values of all realizations at each pixel.\n",
    "\n",
    "with open (Filepath) as fl:\n",
    "    for line in fl:\n",
    "        eles = line.strip().split(' ')\n",
    "       \n",
    "        if len(eles)>=5:    # filter the lines with property name \"Facies unit1 scale1\"        \n",
    "            allele.append(eles)\n",
    "            \n",
    "rlz_no = len(allele[0]) # number of realizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partimgs = np.array(allele, dtype = float).reshape((64, 64, rlz_no)).astype(int)\n",
    "partimgs = np.where(partimgs == 1, 4, partimgs)/2 * 127.5 # originally, 1 for channel sand facies, and 2 for channel bank; here exchange their codes.\n",
    "# The orientation of the original simulated facies models is only from 0-90, thus we enlarge the facies model dataset by reversing it vertically to add facies models with orientation from -90 to 0.  \n",
    "allimgs = np.concatenate((partimgs, partimgs[::-1,:,:]),2)  # partimgs[::-1,:,:] to reverse partimgs vertically: original partimgs \n",
    "allimgs = np.transpose(allimgs, (2, 0, 1))  # transpose into (?, 64, 64) dimension\n",
    "allimgs = allimgs.reshape(-1, 1, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(allimgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(allele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Generate probability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(([allimgs.shape[0]]+[8]+[*allimgs.shape[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define Guassian kernel\n",
    "from scipy.stats import multivariate_normal\n",
    "def norm_kernel(size = 9, sigma = 2):\n",
    "    sig = sigma * np.eye(2)\n",
    "    mean = np.zeros(2,)\n",
    "    size_min = -(size - 1)/2\n",
    "    size_max = (size - 1)/2\n",
    "    x = np.linspace(size_min, size_max, size)\n",
    "    y = np.linspace(size_min, size_max, size)\n",
    "    xk, yk = np.meshgrid(x, y)\n",
    "    kernel = np.zeros((size,size), dtype=np.float32)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            coord = np.squeeze([xk[i,j], yk[i,j]])\n",
    "            kernel[i,j] = multivariate_normal.pdf(coord, mean=mean, cov=sig)\n",
    "    kernel_sum = np.sum(kernel)\n",
    "    kernel = kernel / kernel_sum\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Gaussian kernels with various size to smooth the indicator of channel complex to form the probability maps of channel complex with various blurriness. \n",
    "\n",
    "import scipy.signal as sig\n",
    "prob_rlzs = np.zeros(([allimgs.shape[0]]+[8]+[*allimgs.shape[1:]]), dtype=np.float32) # dimension = [35640, 8, 1, 64, 64]  \n",
    "count = 0\n",
    "for k in range(13,28,2):\n",
    "    kernel = norm_kernel(size = k, sigma = k)  # size should be set to be odd\n",
    "    for num in range(allimgs.shape[0]):\n",
    "        cur_image = allimgs[num,0]/255.0\n",
    "        padvalue = np.mean(cur_image)\n",
    "        prob_image = sig.convolve2d(cur_image, kernel, fillvalue = padvalue, mode='same') \n",
    "        prob_rlzs[num, count, 0] = prob_image \n",
    "            \n",
    "    count = count + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(prob_rlzs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test synthesized probability maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(allimgs[652,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, sharex='col', sharey='row')\n",
    "fig.set_size_inches(10.5, 10.5, forward=True)\n",
    "  \n",
    "for i in range (2):\n",
    "  for j in range(4):\n",
    "    ax[i, j].imshow(prob_rlzs[652, i*4 + j,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_rlzs = prob_rlzs.reshape(-1,1, 64, 64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prob_rlzs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Generate well facies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random well points\n",
    "\n",
    "well_points = np.zeros(prob_rlzs.shape, dtype = int)\n",
    "for i in range(prob_rlzs.shape[0]):\n",
    "    well_points_num = np.random.choice(np.arange(1, 21), 1)  # Random choose the expected total number of well points\n",
    "    xs = np.random.choice(64, well_points_num)\n",
    "    ys = np.random.choice(64, well_points_num)\n",
    "    well_points[i, 0, xs, ys] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prob_rlzs_max = np.max(prob_rlzs, axis = (2, 3), keepdims = True)\n",
    "Prob_rlzs_min = np.min(prob_rlzs, axis = (2, 3), keepdims = True)\n",
    "well_facies = well_points * (prob_rlzs - Prob_rlzs_min)/(Prob_rlzs_max - Prob_rlzs_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample well facies according to calculated probability maps.\n",
    "well_facies = np.where(well_facies<=0.4, 0, well_facies)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(well_facies[664,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "well_facies_random = np.random.uniform(0,1,well_facies.shape)\n",
    "well_facies = np.where(well_facies_random<well_facies, 1, 0) + well_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test synthesized well facies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prob_rlzs[28994,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(well_facies[28994,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Load labels (Global features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_list=[]  # store all labels of the file. \n",
    "with open (labels_path) as lb:  # read label file\n",
    "    for line in lb:\n",
    "        labels_list.append(line.strip().split('  '))\n",
    "\n",
    "ori_labels_no = len(labels_list) # number of labels in the opened file\n",
    "ori_labels_arr=np.array(labels_list, dtype=np.float).reshape(ori_labels_no, 5).astype(np.float)\n",
    "\n",
    "all_labels_arr = np.empty((ori_labels_no*6,5), dtype=np.float)\n",
    "\n",
    "# Every label corresponds to 3 consecutive facies models, thus labels are mutiplied by 3.\n",
    "all_labels_arr[:ori_labels_no*3:3,:]=ori_labels_arr\n",
    "all_labels_arr[1:ori_labels_no*3:3,:]=ori_labels_arr\n",
    "all_labels_arr[2:ori_labels_no*3:3,:]=ori_labels_arr\n",
    "\n",
    "# When facies models are enlarged by reversing vertically; the orientation of reversed facies models is from -90 to 0 degree. \n",
    "all_labels_arr[:,1]=all_labels_arr[:,1]*(-1) # orientation is negativized. \n",
    "\n",
    "# Other labels for the reversed facies models remain the same. \n",
    "all_labels_arr[ori_labels_no*3:ori_labels_no*6:3,:]=ori_labels_arr\n",
    "all_labels_arr[ori_labels_no*3+1:ori_labels_no*6:3,:]=ori_labels_arr\n",
    "all_labels_arr[ori_labels_no*3+2:ori_labels_no*6:3,:]=ori_labels_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_cor = np.empty((all_labels_arr.shape[0], 4), dtype=np.float)  \n",
    "orit = all_labels_arr[:, 1]   # Orientation is placed in the first column\n",
    "\n",
    "# labels_cor include orientation of channels, inter-channel mud facies ratio, width of channel sand, and sinuosity index (amplitude/wavelength) of channel sand\n",
    "# at the range of -1 to 1\n",
    "labels_cor[:,0] = ((orit - np.min(orit))/(np.max(orit) - np.min(orit)) - 0.5) * 2  \n",
    "\n",
    "back_ratio = 1-np.count_nonzero(allimgs, (1,2,3))/(64*64)\n",
    "labels_cor[:,1] = ((back_ratio - np.min(back_ratio))/(np.max(back_ratio) - np.min(back_ratio)) - 0.5) * 2\n",
    "\n",
    "width = all_labels_arr[:, 2]\n",
    "labels_cor[:,2] = ((width - np.min(width ))/(np.max(width ) - np.min(width )) - 0.5) * 2\n",
    "    \n",
    "amwv_ratio = all_labels_arr[:, 4]/all_labels_arr[:, 3]  #amplitude to wavelength ratio\n",
    "### Important: set amplitude/wavelength to be 0.55 when it is larger than 0.55, because the sinuosity level of channels can not be more apparent even when that ratio is larger.\n",
    "amwv_ratio = np.where(amwv_ratio> 0.55, 0.55, amwv_ratio)\n",
    "labels_cor[:,3] = ((amwv_ratio  - np.min(amwv_ratio ))/(np.max(amwv_ratio ) - np.min(amwv_ratio )) - 0.5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Generate training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split facies models into training and test dataset\n",
    "randseq=np.random.RandomState(232).permutation(allimgs.shape[0])\n",
    "allimgs_training = allimgs[randseq[:32640]]\n",
    "allimgs_test = allimgs[randseq[32640:]]\n",
    "print(allimgs_training.shape)\n",
    "print(allimgs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding split global features into training and test dataset\n",
    "labels_cor_training = labels_cor[randseq[:32640]]\n",
    "labels_cor_test = labels_cor[randseq[32640:]]\n",
    "print(labels_cor_training.shape)\n",
    "print(labels_cor_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 Building consistent training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This block is used when building consistent training dataset, where facies models, global features, well facies, and probmaps are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Randomly split probability maps into training and test dataset\n",
    "prob_rlzs=prob_rlzs.reshape(-1,8, 64, 64) \n",
    "prob_rlzs_training = prob_rlzs[randseq[:32640]].reshape(-1,1, 64, 64)\n",
    "prob_rlzs_test = prob_rlzs[randseq[32640:]].reshape(-1,1, 64, 64)\n",
    "\n",
    "# Randomly split well facies data into training and test dataset\n",
    "well_facies=well_facies.reshape(-1, 8, 64, 64)\n",
    "well_facies_training = well_facies[randseq[:32640]].reshape(-1,1, 64, 64)\n",
    "well_facies_test = well_facies[randseq[32640:]].reshape(-1,1, 64, 64)\n",
    "\n",
    "# Keep random one of the 8 probmaps and one of the 8 well facies data in training dataset. Test dataset still have 8 probmaps and 8 well facies\n",
    "proborder = np.arange(32640) * 8 + np.random.RandomState(32).randint(0, 8, size=32640)\n",
    "prob_rlzs_training = prob_rlzs_training[proborder]\n",
    "well_facies_training = well_facies_training[proborder]\n",
    "\n",
    "print(prob_rlzs_training.shape)\n",
    "print(well_facies_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(allimgs_training[1225,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_cor[randseq[1225]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_cor_training[1225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prob_rlzs_training[1225,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(well_facies_training[1225,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 Building non-consistent training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This block is used when building non-consistent training dataset, where only facies models and global features are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split probability maps into training and test dataset\n",
    "# prob_rlzs=prob_rlzs.reshape(-1,8, 64, 64) \n",
    "# prob_rlzs_training = prob_rlzs[randseq[:32640]].reshape(-1,1, 64, 64)\n",
    "# prob_rlzs_test = prob_rlzs[randseq[32640:]].reshape(-1,1, 64, 64)\n",
    "# print(prob_rlzs_training.shape)\n",
    "# print(prob_rlzs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle probability maps again, there are 8 probability maps correpsonding to 1 facies models, and the 8 maps are in order\n",
    "# prob_randseq=np.random.permutation(prob_rlzs_training.shape[0])\n",
    "# prob_rlzs_training = prob_rlzs_training[prob_randseq] \n",
    "\n",
    "# Randomly split well facies data into training and test dataset\n",
    "# well_facies=well_facies.reshape(-1, 8, 64, 64)\n",
    "# well_facies_training = well_facies[randseq[:32640]].reshape(-1,1, 64, 64)\n",
    "# well_facies_test = well_facies[randseq[32640:]].reshape(-1,1, 64, 64)\n",
    "# print(well_facies_training.shape)\n",
    "# print(well_facies_test.shape)\n",
    "\n",
    "# well_facies_training = well_facies_training[prob_randseq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(well_facies_training.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Store training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# copy from ProGAN github dataset_tools.py\n",
    "class TFRecordExporter:\n",
    "    def __init__(self, tfrecord_dir, expected_images, print_progress=True, progress_interval=10):\n",
    "        self.tfrecord_dir       = tfrecord_dir\n",
    "        self.tfr_prefix         = os.path.join(self.tfrecord_dir, os.path.basename(self.tfrecord_dir))\n",
    "        self.expected_images    = expected_images\n",
    "        self.cur_images         = 0\n",
    "        self.shape              = None\n",
    "        self.resolution_log2    = None\n",
    "        self.tfr_writers        = []\n",
    "        self.print_progress     = print_progress\n",
    "        self.progress_interval  = progress_interval\n",
    "        if self.print_progress:\n",
    "            print('Creating dataset \"%s\"' % tfrecord_dir)\n",
    "        if not os.path.isdir(self.tfrecord_dir):\n",
    "            os.makedirs(self.tfrecord_dir)\n",
    "        assert(os.path.isdir(self.tfrecord_dir))\n",
    "        \n",
    "    def close(self):\n",
    "        if self.print_progress:\n",
    "            print('%-40s\\r' % 'Flushing data...', end='', flush=True)\n",
    "        for tfr_writer in self.tfr_writers:\n",
    "            tfr_writer.close()\n",
    "        self.tfr_writers = []\n",
    "        if self.print_progress:\n",
    "            print('%-40s\\r' % '', end='', flush=True)\n",
    "            print('Added %d images.' % self.cur_images)\n",
    "\n",
    "    def choose_shuffled_order(self): # Note: Images and labels must be added in shuffled order.\n",
    "        order = np.arange(self.expected_images)\n",
    "        np.random.RandomState(123).shuffle(order)\n",
    "        return order\n",
    "\n",
    "    def add_real_image(self, real_img):\n",
    "        if self.print_progress and self.cur_images % self.progress_interval == 0:\n",
    "            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n",
    "        if self.shape is None:\n",
    "            self.shape = real_img.shape\n",
    "            self.resolution_log2 = int(np.log2(self.shape[1]))\n",
    "            assert self.shape[0] in [1, 3]\n",
    "            assert self.shape[1] == self.shape[2]\n",
    "            assert self.shape[1] == 2**self.resolution_log2\n",
    "            tfr_opt = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n",
    "            for lod in range(self.resolution_log2 - 1):\n",
    "                tfr_file = self.tfr_prefix + '-1r%02d.tfrecords' % (self.resolution_log2 - lod)\n",
    "                self.tfr_writers.append(tf.python_io.TFRecordWriter(tfr_file, tfr_opt))\n",
    "            self.tfr_writers.append(tf.python_io.TFRecordWriter(tfr_file, tfr_opt))\n",
    "        assert real_img.shape == self.shape\n",
    "        for lod, tfr_writer in enumerate(self.tfr_writers[:-1]):\n",
    "            if lod:\n",
    "                real_img = real_img.astype(np.float32)\n",
    "                \n",
    "                # used to produce low-D with most frequent facies code\n",
    "                #real_img_t = np.expand_dims(real_img, axis = 3)\n",
    "                #real_img_t_c = np.concatenate((real_img_t[:, 0::2, 0::2], real_img_t[:, 0::2, 1::2], real_img_t[:, 1::2, 0::2], real_img_t[:, 1::2, 1::2]), axis = 3)                \n",
    "                #mode, _ = stats.mode(real_img_t_c, axis = 3)\n",
    "                #real_img = np.squeeze(mode, axis = 3)\n",
    "                \n",
    "                # used to produce low-D with averaging method\n",
    "                real_img = (real_img[:, 0::2, 0::2] + real_img[:, 0::2, 1::2] + real_img[:, 1::2, 0::2] + real_img[:, 1::2, 1::2]) * 0.25\n",
    "            \n",
    "            quant = np.rint(real_img).clip(0, 255).astype(np.uint8)\n",
    "            ex = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n",
    "                'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
    "            tfr_writer.write(ex.SerializeToString())\n",
    "        self.cur_images += 1\n",
    "        \n",
    "        \n",
    "    def add_prob_image(self, prob_image):\n",
    "        if self.print_progress and self.cur_images % self.progress_interval == 0:\n",
    "            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n",
    "        if self.shape is None:\n",
    "            self.shape = prob_image.shape\n",
    "            tfr_opt = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n",
    "            # add probimages writer into self.tfr_writers    \n",
    "            tfr_file = self.tfr_prefix + '-2probimages.tfrecords' \n",
    "            self.tfr_writers.append(tf.python_io.TFRecordWriter(tfr_file, tfr_opt))\n",
    "        # Writting prob_image into tfrecord file\n",
    "        quant = prob_image.clip(0, 1).astype(np.float16)\n",
    "        ex = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n",
    "            'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
    "        self.tfr_writers[0].write(ex.SerializeToString())\n",
    "        self.cur_images += 1           \n",
    "\n",
    "    def add_well_facies(self, well_facies):\n",
    "        if self.print_progress and self.cur_images % self.progress_interval == 0:\n",
    "            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n",
    "        if self.shape is None:\n",
    "            self.shape = well_facies.shape\n",
    "            tfr_opt = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n",
    "            # add well_facies writer into self.tfr_writers    \n",
    "            tfr_file = self.tfr_prefix + '-3wellfacies.tfrecords' \n",
    "            self.tfr_writers.append(tf.python_io.TFRecordWriter(tfr_file, tfr_opt))\n",
    "        # Writting well_facies into tfrecord file\n",
    "        quant = well_facies.astype(np.uint8)\n",
    "        ex = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n",
    "            'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
    "        self.tfr_writers[0].write(ex.SerializeToString())\n",
    "        self.cur_images += 1           \n",
    "        \n",
    "        \n",
    "    def add_labels(self, labels):\n",
    "        if self.print_progress:\n",
    "            print('%-40s\\r' % 'Saving labels...', end='', flush=True)\n",
    "        assert labels.shape[0] == self.cur_images\n",
    "        with open(self.tfr_prefix + '-4rxx.labels', 'wb') as f:\n",
    "            np.save(f, labels.astype(np.float32))\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordExporter(tfrecord_dir_training, allimgs_training.shape[0]) as tfr:\n",
    "    order = tfr.choose_shuffled_order()\n",
    "    for idx in range(order.size):\n",
    "        tfr.add_real_image(allimgs_training[order[idx]])\n",
    "    tfr.add_labels(labels_cor_training[order])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordExporter(tfrecord_dir_training, prob_rlzs_training.shape[0]) as tfr:\n",
    "    for idx in range(prob_rlzs_training.shape[0]):\n",
    "        tfr.add_prob_image(prob_rlzs_training[idx])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordExporter(tfrecord_dir_training, well_facies_training.shape[0]) as tfr:\n",
    "    for idx in range(well_facies_training.shape[0]):\n",
    "        tfr.add_well_facies(well_facies_training[idx])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Store test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordExporter(tfrecord_dir_test, allimgs_test.shape[0]) as tfr:\n",
    "    for idx in range(allimgs_test.shape[0]):\n",
    "        tfr.add_real_image(allimgs_test[idx])\n",
    "    tfr.add_labels(labels_cor_test)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordExporter(tfrecord_dir_test, prob_rlzs_test.shape[0]) as tfr:\n",
    "    for idx in range(prob_rlzs_test.shape[0]):\n",
    "        tfr.add_prob_image(prob_rlzs_test[idx])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordExporter(tfrecord_dir_test, well_facies_test.shape[0]) as tfr:\n",
    "    for idx in range(well_facies_test.shape[0]):\n",
    "        tfr.add_well_facies(well_facies_test[idx])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
