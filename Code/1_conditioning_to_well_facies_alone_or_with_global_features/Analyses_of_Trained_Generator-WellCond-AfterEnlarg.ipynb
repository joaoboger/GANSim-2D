{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "tf.disable_v2_behavior()\n",
    "import PIL.Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the path to directory containing code of this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_path = 'H:\\\\repos\\\\GeoModeling_GANSim-2D_Condition_to_Well_Facies_and_Global_Features\\\\Code\\\\1_conditioning_to_well_facies_alone_or_with_global_features\\\\'\n",
    "sys.path.append(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the path to data directory; this directory includes two datasets: \"trainingdata\" and \"testdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir_test = 'H:\\\\repos\\\\GeoModeling_GANSim-2D_Condition_to_Well_Facies_and_Global_Features\\\\TrainingData\\\\DataSets(MultiChannels_Version4_Consistency)\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set path to trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 19200 means totally 19200 thousand training images (facies models) used for the training\n",
    "network_dir = 'H:\\\\repos\\\\GeoModeling_GANSim-2D_Condition_to_Well_Facies_and_Global_Features\\\\TrainingResults\\\\2_GANs conditioned to well facies\\After well area  enlargement\\\\009-pgan-conditionalWellEnlargement-2gpu\\\\'\n",
    "network_name = 'network-snapshot-016000.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorFlow session.\n",
    "tf.InteractiveSession()\n",
    "\n",
    "import dataset\n",
    "# tfrecord_dir='TestData' to fetch test dataset, if tfrecord_dir='TrainingData' to fetch training dataset\n",
    "# labeltypes: 0 for 'channelorientation', 1 for 'mudproportion', 2 for 'channelwidth', 3 for 'channelsinuosity'\n",
    "# well_enlarge: if True, well points occupy 4x4 area, otherwise occupy 1x1 area\n",
    "test_set = dataset.load_dataset(data_dir=data_dir_test, verbose=True, tfrecord_dir='TestData', labeltypes = [1,2,3], well_enlarge = True, shuffle_mb = 0, prefetch_mb = 0)\n",
    "\n",
    "# labels are from -1 to 1\n",
    "image_test, label_test = test_set.get_minibatch_imageandlabel_np(3000)  \n",
    "probimg_test, wellfacies_test = test_set.get_minibatch_probandwell_np(3000*8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(image_test.shape)\n",
    "print(label_test.shape)\n",
    "print(probimg_test.shape)\n",
    "print(wellfacies_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wellfacies_test[60,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_test[60,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global features are kept and inputted into Networks with the scale of -1 to 1. To recover the global features into its original scales, use the below transformation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#orit_test = (label_test[:,0]/2+0.5)*168-84\n",
    "back_ratio_test = (label_test[:,0]/2+0.5)*0.8037109375+0.167724609375\n",
    "width_test = (label_test[:,1]/2+0.5)*0.8+2.7\n",
    "amwv_ratio_test = (label_test[:,2]/2+0.5)*0.4866197183098592+0.06338028169014084"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import pre-trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorFlow session.\n",
    "tf.InteractiveSession()\n",
    "\n",
    "# Import networks.\n",
    "with open(network_dir+network_name, 'rb') as file:\n",
    "    G, D, Gs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "### 3. Random simulate based on pretrained Network and mannual inspection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly sample well facies from test facies models **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "well_points = np.zeros([32, 1, 64, 64], dtype = int)\n",
    "for i in range(32):\n",
    "    well_points_num = np.random.RandomState(3*i).choice(np.arange(5, 8), 1)  # Random choose the expected total number of well points\n",
    "    xs = np.random.RandomState(i*i*i*56).choice(64, well_points_num)\n",
    "    ys = np.random.RandomState(i*i*2+20).choice(64, well_points_num)\n",
    "    well_points[i, 0, xs, ys] = 1\n",
    "\n",
    "well_facies = np.where(well_points * image_test[:32]>0, 1, 0) # image_test is from 0 to 155\n",
    "well_facies = np.concatenate([well_points, well_facies], 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to show well facies code\n",
    "plt.imshow((well_facies[0, 1] + 1) * well_facies[0, 0])\n",
    "plt.colorbar()\n",
    "#plt.savefig(network_dir + \"Tested well facies.png\", dpi=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Enlarge areas of well points into 4 x 4 as inputs\n",
    "with tf.device('/gpu:0'):\n",
    "    well_facies = tf.cast(well_facies, tf.float32)\n",
    "    well_facies_enlarge = tf.nn.max_pool(well_facies, ksize = [1,1,4,4], strides=[1,1,1,1], padding='SAME', data_format='NCHW') \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    well_facies_el = sess.run(well_facies_enlarge)\n",
    "\n",
    "# make mask of output well facies data only for better displaying in following figure\n",
    "well_facies_onechannel = well_facies[:,0:1]+well_facies[:,1:2]\n",
    "well_facies_onechannel_mask = np.ma.masked_where(well_facies_onechannel.eval() == 0, well_facies_onechannel.eval()) # Had to convert Tensors using .eval()\n",
    "well_facies_el_onechannel = well_facies_el[:,0:1]+well_facies_el[:,1:2]\n",
    "well_facies_el_onechannel_mask = np.ma.masked_where(well_facies_el_onechannel == 0, well_facies_el_onechannel)\n",
    "cmap_well = plt.cm.viridis  # Can be any colormap that you want after the cm   '.\n",
    "cmap_well.set_bad(color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Gs.input_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each row has the same input well facies data but different latent vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 9, sharex='col', sharey='row')\n",
    "fig.set_size_inches(12, 10.5, forward=True)\n",
    "\n",
    "for i in range (8):\n",
    "    ax[i, 0].imshow(well_facies_el_onechannel_mask[i,0], cmap=cmap_well, vmin=1, vmax=2.2)\n",
    "    \n",
    "    latents_plt = np.random.randn(500, Gs.input_shapes[0][1]) \n",
    "    labels_plt = np.random.uniform(-1, 1, (500, 0))  \n",
    "    well_facies_plt = np.repeat(well_facies_el[i:i+1], 500, axis=0)\n",
    "\n",
    "    # Run the generator to produce a set of images.\n",
    "    images_plt = Gs.run(latents_plt, labels_plt, well_facies_plt) #, probimages_plt\n",
    "    images_plt = np.where(images_plt< -0.7, -1, images_plt)\n",
    "    images_plt = np.where(images_plt> 0.3, 1, images_plt)\n",
    "    images_plt = np.where((images_plt>= -0.4) & (images_plt<= 0.4), 0, images_plt)\n",
    "    \n",
    "    images_plt_a = (np.where(images_plt> -0.4, 1, images_plt) + 1)/2\n",
    "    images_plt_average = np.average(images_plt_a, axis = 0)\n",
    "    images_plt_variance = np.var(images_plt_a, axis = 0)\n",
    "    \n",
    "    for j in range(6):\n",
    "        ax[i, j+1].imshow(images_plt[j,0,:,:])\n",
    "    ax[i, 7].imshow(images_plt_average[0], vmin = 0, vmax = 1)   # E-type\n",
    "    ax[i, 8].imshow(images_plt_variance[0], vmin = 0, vmax = 0.25)  # Variance\n",
    "# plt.savefig(network_dir + \"simulations conditioned to well facies.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Quantitative assessment of well facies reproduction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_well_facies_data(images_num):\n",
    "    well_points = np.zeros([images_num, 1, 64, 64], dtype = int)\n",
    "    for i in range(images_num):\n",
    "        well_points_num = np.random.RandomState(3*i).choice(np.arange(8, 16), 1)  # Random choose the expected total number of well points\n",
    "        xs = np.random.choice(64, well_points_num)\n",
    "        ys = np.random.choice(64, well_points_num)\n",
    "        well_points[i, 0, xs, ys] = 1\n",
    "\n",
    "    # Using training facies models to sample faices types at well  points\n",
    "    well_facies = np.where(well_points * image_test[:images_num]>0, 1, 0)\n",
    "    well_facies = np.concatenate([well_points, well_facies], 1)      \n",
    " \n",
    "    return well_facies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_images(realization_num, well_facies):\n",
    "    # Generate latent vectors.\n",
    "    latents_plt = np.random.randn(realization_num, Gs.input_shapes[0][1]) \n",
    "    labels_plt =  np.random.uniform(-1, 1, (realization_num, 0)) \n",
    "    well_facies_plt = well_facies\n",
    "\n",
    "    # Run the generator to produce a set of images.\n",
    "    images_plt = Gs.run(latents_plt, labels_plt, well_facies_plt)\n",
    "    images_plt = np.where(images_plt< -0.3, -1, images_plt)\n",
    "    images_plt = np.where(images_plt> 0.15, 1, images_plt)\n",
    "    images_plt = np.where((images_plt>= -0.3) & (images_plt<= 0.15), 0, images_plt)\n",
    "    return images_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def well_points_accuracy(well_facies, fake_imgs_a):\n",
    "    gg = well_facies_smp_train_facies[:,0:1] + well_facies_smp_train_facies[:,1:2]\n",
    "    \n",
    "    recognized_f1 = np.where((gg==2) & (well_facies_smp_train_facies[:,0:1] * (fake_imgs_a+1) > 0.8), 1, 0)\n",
    "    f1_prob = np.sum(recognized_f1)/np.sum(np.where(gg==2,1,0))\n",
    "\n",
    "    recognized_f0 = np.where((gg==1) & (well_facies_smp_train_facies[:,0:1] * (fake_imgs_a+2) ==1), 1, 0)\n",
    "    f0_prob = np.sum(recognized_f0)/np.sum(np.where(gg==1,1,0))\n",
    "    \n",
    "    return f1_prob, f0_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enlarge(well_facies):\n",
    "    ### Enlarge areas of well points into 4 x 4 as inputs\n",
    "    with tf.device('/gpu:0'):\n",
    "        well_facies = tf.cast(well_facies, tf.float32)\n",
    "        well_facies_enlarge = tf.nn.max_pool(well_facies, ksize = [1,1,4,4], strides=[1,1,1,1], padding='SAME', data_format='NCHW') \n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        well_points_el = sess.run(well_facies_enlarge) \n",
    "    return well_points_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_num = 100\n",
    "well_facies_smp_train_facies = get_random_well_facies_data(images_num)\n",
    "well_facies_smp_train_facies_el = enlarge(well_facies_smp_train_facies)      \n",
    "fake_imgs = generate_images(images_num, well_facies_smp_train_facies_el)\n",
    "f_c_prob, f_m_prob = well_points_accuracy(well_facies_smp_train_facies, fake_imgs)\n",
    "print(f_c_prob) # well facies reproduction accuracy for input channel complex facies\n",
    "print(f_m_prob) # well facies reproduction accuracy for input mud facies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Application and label conditioning accuracy analyses of Trained model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
